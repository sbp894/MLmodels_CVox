{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load required packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import h5py\n",
    "import scipy.io\n",
    "import matlab_helpers as mh \n",
    "import tensorflow as tf \n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the names of all mat-files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> all_files_nameonly: len lines= 1605, first line = CarMod_psd_Chut_2_Feb_07_2022_51861688_ms_101198_101787.mat\n",
      "--> CarMod_data_list: len lines= 1605, first line = D:/Dropbox/Python/MLmodels/Datasets/CarModPow/level65_dBspl_clean/Chut/CarMod_psd_Chut_2_Feb_07_2022_51861688_ms_101198_101787.mat\n"
     ]
    }
   ],
   "source": [
    "root_matdata_dir = 'D:/Dropbox/Python/MLmodels/Datasets/CarModPow/'\n",
    "out_ml_dir = root_matdata_dir + 'ml_data_MLP/'\n",
    "if not os.path.exists(out_ml_dir):\n",
    "    os.makedirs(out_ml_dir)\n",
    "\n",
    "clean_in_data_dir = root_matdata_dir + 'level65_dBspl_clean/'\n",
    "valid_datadirs = ['Chut', 'HighWhistle', 'Rumble', 'Tchatter', 'Wheek', 'Whine']\n",
    "calls2use = ['Chut', 'Rumble', 'Wheek', 'Whine']\n",
    "\n",
    "all_files_nameonly= []\n",
    "CarMod_data_list= []\n",
    "\n",
    "for cur_call_dir in valid_datadirs:\n",
    "    cur_call_path = clean_in_data_dir + cur_call_dir + '/' \n",
    "    # print(cur_call_path)\n",
    "    cur_dir_files = [f for f in os.listdir(cur_call_path) if os.path.isfile(os.path.join(cur_call_path, f))]\n",
    "    all_files_nameonly = all_files_nameonly + cur_dir_files\n",
    "    CarMod_data_list = CarMod_data_list + [cur_call_path + f for f in cur_dir_files]\n",
    "    \n",
    "\n",
    "print(f\"--> all_files_nameonly: len lines= {len(all_files_nameonly)}, first line = {all_files_nameonly[0]}\")\n",
    "print(f\"--> CarMod_data_list: len lines= {len(CarMod_data_list)}, first line = {CarMod_data_list[0]}\")\n",
    "\n",
    "out_allfiles_txt_fname = out_ml_dir + 'all_CarPow_data_list.txt'\n",
    "with open(out_allfiles_txt_fname, 'w') as f:\n",
    "    for line in CarMod_data_list:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Mat files and then create .h5 files for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m post_search_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/CarMod_\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m fName \u001b[39min\u001b[39;00m CarMod_data_list:\n\u001b[1;32m----> 7\u001b[0m     data \u001b[39m=\u001b[39m mh\u001b[39m.\u001b[39;49mloadmat(fName)\n\u001b[0;32m      8\u001b[0m     data_CarMod_x\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mravel(data[\u001b[39m\"\u001b[39m\u001b[39mCarMod_power\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mCarMod_power\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[0;32m     10\u001b[0m data_label_name \u001b[39m=\u001b[39m [item[item\u001b[39m.\u001b[39mrfind(pre_search_str)\u001b[39m+\u001b[39m\u001b[39mlen\u001b[39m(pre_search_str):item\u001b[39m.\u001b[39mrfind(post_search_str)] \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m CarMod_data_list]\n",
      "File \u001b[1;32md:\\Dropbox\\Python\\MLmodels\\Code\\matlab_helpers.py:10\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloadmat\u001b[39m(filename):\n\u001b[0;32m      4\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m    this function should be called instead of direct spio.loadmat\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m    as it cures the problem of not properly recovering python dictionaries\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m    from mat files. It calls the function check keys to cure all entries\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m    which are still mat-objects\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     data \u001b[39m=\u001b[39m spio\u001b[39m.\u001b[39;49mloadmat(filename, struct_as_record\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, squeeze_me\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     11\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_keys(data)\n",
      "File \u001b[1;32mc:\\Users\\spsat\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:224\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[39mLoad MATLAB file.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m variable_names \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mvariable_names\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 224\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    225\u001b[0m     MR, _ \u001b[39m=\u001b[39m mat_reader_factory(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    226\u001b[0m     matfile_dict \u001b[39m=\u001b[39m MR\u001b[39m.\u001b[39mget_variables(variable_names)\n",
      "File \u001b[1;32mc:\\Users\\spsat\\anaconda3\\envs\\tf-gpu\\lib\\contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[0;32m    118\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[0;32m    120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\spsat\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m@contextmanager\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> 17\u001b[0m     f, opened \u001b[39m=\u001b[39m _open_file(file_like, appendmat, mode)\n\u001b[0;32m     18\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m         \u001b[39myield\u001b[39;00m f\n",
      "File \u001b[1;32mc:\\Users\\spsat\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[39mreturn\u001b[39;00m file_like, \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_like, mode), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     41\u001b[0m     \u001b[39m# Probably \"not found\"\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(file_like, \u001b[39mstr\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "out_CarMod_data_file = out_ml_dir + 'all_CarMod_data.h5'\n",
    "data_CarMod_x = []\n",
    "pre_search_str = 'clean/'\n",
    "post_search_str = '/CarMod_'\n",
    "\n",
    "for fName in CarMod_data_list:\n",
    "    data = mh.loadmat(fName)\n",
    "    data_CarMod_x.append(np.ravel(data[\"CarMod_power\"][\"CarMod_power\"]))\n",
    "    \n",
    "data_label_name = [item[item.rfind(pre_search_str)+len(pre_search_str):item.rfind(post_search_str)] for item in CarMod_data_list]\n",
    "data_label_y = len(calls2use)*np.ones((len(data_CarMod_x),1))\n",
    "unq_vals, unq_counts = np.unique(data_label_y, return_counts=True)\n",
    "print(dict(zip(unq_vals,unq_counts)))\n",
    "\n",
    "for ind, cur_call in zip(np.arange(len(data_label_name)),data_label_name):\n",
    "    if cur_call in calls2use: \n",
    "        data_label_y[ind,0] = calls2use.index(cur_call)\n",
    "\n",
    "data_CarMod_x = np.array(data_CarMod_x)\n",
    "data_label_y = np.array(data_label_y).astype(int)\n",
    "\n",
    "print(f\"data_CarMod_x={type(data_CarMod_x)}&{len(data_CarMod_x)},data_label_y={type(data_label_y)}&{data_label_y.shape},\")\n",
    "\n",
    "if (not os.path.exists(out_CarMod_data_file)):\n",
    "    print(\"Saving file\" + out_CarMod_data_file)\n",
    "    hf = h5py.File(out_CarMod_data_file, \"w\")\n",
    "    hf.create_dataset('data_CarMod_x',data=data_CarMod_x)\n",
    "    hf.create_dataset('data_label_y',data=data_label_y)\n",
    "    hf.close()\n",
    "else: \n",
    "    print(\"File (\" + out_CarMod_data_file + \") already exists\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9901b0122a0103a0e954f0712b860e20e1581f681d96d994631537742cd9f65d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
