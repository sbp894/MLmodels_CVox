{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to create HDF5 datasets (at different SNRs) for vIHC-based PSD data \n",
    "Notebook outline: \n",
    "1. Load required packages \n",
    "2. Define a function to create dataset for a single SNR \n",
    "3. Loop through SNRs to create different hdf5 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import h5py\n",
    "import scipy.io\n",
    "import matlab_helpers as mh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define a function to create dataset for a single SNR \n",
    "Steps are \n",
    "* Read SNR \n",
    "* Define the right input and output directories/files \n",
    "* Read all data \n",
    "* Save HDF5 (X, Y, and filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_snr_data(snr_value, forceReDo):\n",
    "    root_in_dir= '../Datasets/psd_gp_vIHC_mat/'\n",
    "    root_out_dir= '../Datasets/psd_gp_vIHC_mat/PyData/'\n",
    "    if not os.path.exists(root_out_dir):\n",
    "        os.makedirs(root_out_dir)\n",
    "    \n",
    "    if np.isinf(snr_value):\n",
    "        root_matdata_dir = root_in_dir + 'level65_dBspl_clean/'\n",
    "        out_allfiles_txt_fname = root_out_dir + 'PSD_data_list_clean.txt'\n",
    "        out_psd_data_file = root_out_dir + 'PSD_data_clean.h5'\n",
    "        pre_search_str = '_clean/'\n",
    "    else:\n",
    "        root_matdata_dir = root_in_dir + 'level65_dBspl_SNR' + snr_value.astype('int').astype('str') + '_white/'\n",
    "        out_allfiles_txt_fname = root_out_dir + 'PSD_data_list_SNR' + snr_value.astype('int').astype('str') + '.txt'\n",
    "        out_psd_data_file = root_out_dir + 'PSD_data_SNR' + snr_value.astype('int').astype('str') + '.h5'\n",
    "        pre_search_str = '_white/'\n",
    "\n",
    "    post_search_str = '/psd_'\n",
    "\n",
    "    if (not os.path.exists(out_psd_data_file)) or forceReDo:\n",
    "        if os.path.exists(root_matdata_dir):\n",
    "            print(f\"Working on: {root_matdata_dir}\")\n",
    "        else:\n",
    "            print(f\"Nooooooooo: {root_matdata_dir}\")\n",
    "\n",
    "        valid_datadirs = ['Chut', 'HighWhistle', 'Rumble', 'Tchatter', 'Wheek', 'Whine']\n",
    "        calls2use = ['Chut', 'Rumble', 'Wheek', 'Whine']\n",
    "\n",
    "        all_files_nameonly= []\n",
    "        psd_data_list= []\n",
    "\n",
    "        for cur_call_dir in valid_datadirs:\n",
    "            cur_call_path = root_matdata_dir + cur_call_dir + '/' \n",
    "            # print(cur_call_path)\n",
    "            cur_dir_files = [f for f in os.listdir(cur_call_path) if os.path.isfile(os.path.join(cur_call_path, f))]\n",
    "            all_files_nameonly = all_files_nameonly + cur_dir_files\n",
    "            psd_data_list = psd_data_list + [cur_call_path + f for f in cur_dir_files]\n",
    "\n",
    "        print(f\"--> all_files_nameonly: len lines= {len(all_files_nameonly)}, first line = {all_files_nameonly[0]}\")\n",
    "        print(f\"--> psd_data_list: len lines= {len(psd_data_list)}, first line = {psd_data_list[0]}\")\n",
    "\n",
    "        with open(out_allfiles_txt_fname, 'w') as f:\n",
    "            for line in psd_data_list:\n",
    "                f.write(f\"{line}\\n\")\n",
    "\n",
    "        data_psd_x = []\n",
    "        for fName in psd_data_list:\n",
    "            data = mh.loadmat(fName)\n",
    "            data_psd_x.append(data[\"psd_data\"][\"psd\"]) \n",
    "            \n",
    "        data_label_name = [item[item.rfind(pre_search_str)+len(pre_search_str):item.rfind(post_search_str)] for item in psd_data_list]\n",
    "        data_label_y = len(calls2use)*np.ones((len(data_psd_x),1))\n",
    "        unq_vals, unq_counts = np.unique(data_label_y, return_counts=True)\n",
    "        print(dict(zip(unq_vals,unq_counts)))\n",
    "\n",
    "        for ind, cur_call in zip(np.arange(len(data_label_name)),data_label_name):\n",
    "            if cur_call in calls2use: \n",
    "                data_label_y[ind,0] = calls2use.index(cur_call)\n",
    "\n",
    "        data_psd_x = np.array(data_psd_x)\n",
    "        data_label_y = np.array(data_label_y).astype(int)\n",
    "        psd_data_list = np.array(psd_data_list)\n",
    "        print(f\"data_psd_x={type(data_psd_x)}&{len(data_psd_x)},data_label_y={type(data_label_y)}&{data_label_y.shape},\\\n",
    "            psd_data_list={type(psd_data_list)}&{psd_data_list.shape}\")\n",
    "\n",
    "        hf = h5py.File(out_psd_data_file, \"w\")\n",
    "        try:\n",
    "            hf.create_dataset('data_psd_x', data=data_psd_x)\n",
    "            hf.create_dataset('data_label_y', data=data_label_y)\n",
    "            # hf.create_dataset('data_filename', data=psd_data_list)\n",
    "            hf.close()\n",
    "            print(\"Saved file\" + out_psd_data_file)\n",
    "\n",
    "        except:\n",
    "            print(f\"Error trying save {out_psd_data_file}\")\n",
    "            hf.close()\n",
    "\n",
    "    else: \n",
    "        print(\"File (\" + out_psd_data_file + \") already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loop through SNRs to create different hdf5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: ../Datasets/psd_gp_vIHC_mat/level65_dBspl_SNR-20_white/\n",
      "--> all_files_nameonly: len lines= 1605, first line = psd_Chut_2_Feb_07_2022_51861688_ms_101198_101787.mat\n",
      "--> psd_data_list: len lines= 1605, first line = ../Datasets/psd_gp_vIHC_mat/level65_dBspl_SNR-20_white/Chut/psd_Chut_2_Feb_07_2022_51861688_ms_101198_101787.mat\n",
      "{4.0: 1605}\n",
      "data_psd_x=<class 'numpy.ndarray'>&1605,data_label_y=<class 'numpy.ndarray'>&(1605, 1),            psd_data_list=<class 'numpy.ndarray'>&(1605,)\n",
      "Saving file../Datasets/psd_gp_vIHC_mat/PyData/PSD_data_SNR-20.h5\n",
      "Working on: ../Datasets/psd_gp_vIHC_mat/level65_dBspl_SNR-15_white/\n",
      "--> all_files_nameonly: len lines= 1605, first line = psd_Chut_2_Feb_07_2022_51861688_ms_101198_101787.mat\n",
      "--> psd_data_list: len lines= 1605, first line = ../Datasets/psd_gp_vIHC_mat/level65_dBspl_SNR-15_white/Chut/psd_Chut_2_Feb_07_2022_51861688_ms_101198_101787.mat\n",
      "{4.0: 1605}\n",
      "data_psd_x=<class 'numpy.ndarray'>&1605,data_label_y=<class 'numpy.ndarray'>&(1605, 1),            psd_data_list=<class 'numpy.ndarray'>&(1605,)\n",
      "Saving file../Datasets/psd_gp_vIHC_mat/PyData/PSD_data_SNR-15.h5\n",
      "Working on: ../Datasets/psd_gp_vIHC_mat/level65_dBspl_SNR-10_white/\n",
      "--> all_files_nameonly: len lines= 1605, first line = psd_Chut_2_Feb_07_2022_51861688_ms_101198_101787.mat\n",
      "--> psd_data_list: len lines= 1605, first line = ../Datasets/psd_gp_vIHC_mat/level65_dBspl_SNR-10_white/Chut/psd_Chut_2_Feb_07_2022_51861688_ms_101198_101787.mat\n",
      "{4.0: 1605}\n",
      "data_psd_x=<class 'numpy.ndarray'>&1605,data_label_y=<class 'numpy.ndarray'>&(1605, 1),            psd_data_list=<class 'numpy.ndarray'>&(1605,)\n",
      "Saving file../Datasets/psd_gp_vIHC_mat/PyData/PSD_data_SNR-10.h5\n",
      "Working on: ../Datasets/psd_gp_vIHC_mat/level65_dBspl_SNR-5_white/\n",
      "--> all_files_nameonly: len lines= 1605, first line = psd_Chut_2_Feb_07_2022_51861688_ms_101198_101787.mat\n",
      "--> psd_data_list: len lines= 1605, first line = ../Datasets/psd_gp_vIHC_mat/level65_dBspl_SNR-5_white/Chut/psd_Chut_2_Feb_07_2022_51861688_ms_101198_101787.mat\n",
      "{4.0: 1605}\n",
      "data_psd_x=<class 'numpy.ndarray'>&1605,data_label_y=<class 'numpy.ndarray'>&(1605, 1),            psd_data_list=<class 'numpy.ndarray'>&(1605,)\n",
      "Saving file../Datasets/psd_gp_vIHC_mat/PyData/PSD_data_SNR-5.h5\n",
      "Working on: ../Datasets/psd_gp_vIHC_mat/level65_dBspl_SNR0_white/\n",
      "--> all_files_nameonly: len lines= 1605, first line = psd_Chut_2_Feb_07_2022_51861688_ms_101198_101787.mat\n",
      "--> psd_data_list: len lines= 1605, first line = ../Datasets/psd_gp_vIHC_mat/level65_dBspl_SNR0_white/Chut/psd_Chut_2_Feb_07_2022_51861688_ms_101198_101787.mat\n",
      "{4.0: 1605}\n",
      "data_psd_x=<class 'numpy.ndarray'>&1605,data_label_y=<class 'numpy.ndarray'>&(1605, 1),            psd_data_list=<class 'numpy.ndarray'>&(1605,)\n",
      "Saving file../Datasets/psd_gp_vIHC_mat/PyData/PSD_data_SNR0.h5\n",
      "Working on: ../Datasets/psd_gp_vIHC_mat/level65_dBspl_SNR5_white/\n",
      "--> all_files_nameonly: len lines= 1605, first line = psd_Chut_2_Feb_07_2022_51861688_ms_101198_101787.mat\n",
      "--> psd_data_list: len lines= 1605, first line = ../Datasets/psd_gp_vIHC_mat/level65_dBspl_SNR5_white/Chut/psd_Chut_2_Feb_07_2022_51861688_ms_101198_101787.mat\n",
      "{4.0: 1605}\n",
      "data_psd_x=<class 'numpy.ndarray'>&1605,data_label_y=<class 'numpy.ndarray'>&(1605, 1),            psd_data_list=<class 'numpy.ndarray'>&(1605,)\n",
      "Saving file../Datasets/psd_gp_vIHC_mat/PyData/PSD_data_SNR5.h5\n",
      "Working on: ../Datasets/psd_gp_vIHC_mat/level65_dBspl_SNR10_white/\n",
      "--> all_files_nameonly: len lines= 1605, first line = psd_Chut_2_Feb_07_2022_51861688_ms_101198_101787.mat\n",
      "--> psd_data_list: len lines= 1605, first line = ../Datasets/psd_gp_vIHC_mat/level65_dBspl_SNR10_white/Chut/psd_Chut_2_Feb_07_2022_51861688_ms_101198_101787.mat\n",
      "{4.0: 1605}\n",
      "data_psd_x=<class 'numpy.ndarray'>&1605,data_label_y=<class 'numpy.ndarray'>&(1605, 1),            psd_data_list=<class 'numpy.ndarray'>&(1605,)\n",
      "Saving file../Datasets/psd_gp_vIHC_mat/PyData/PSD_data_SNR10.h5\n",
      "Working on: ../Datasets/psd_gp_vIHC_mat/level65_dBspl_clean/\n",
      "--> all_files_nameonly: len lines= 1605, first line = psd_Chut_2_Feb_07_2022_51861688_ms_101198_101787.mat\n",
      "--> psd_data_list: len lines= 1605, first line = ../Datasets/psd_gp_vIHC_mat/level65_dBspl_clean/Chut/psd_Chut_2_Feb_07_2022_51861688_ms_101198_101787.mat\n",
      "{4.0: 1605}\n",
      "data_psd_x=<class 'numpy.ndarray'>&1605,data_label_y=<class 'numpy.ndarray'>&(1605, 1),            psd_data_list=<class 'numpy.ndarray'>&(1605,)\n",
      "Saving file../Datasets/psd_gp_vIHC_mat/PyData/PSD_data_clean.h5\n"
     ]
    }
   ],
   "source": [
    "all_snrs= np.arange(-20.0, 11, 5)\n",
    "all_snrs= np.append(all_snrs, np.inf)\n",
    "forceReDo = True\n",
    "for snr_val in all_snrs:\n",
    "    save_snr_data(snr_val,forceReDo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
